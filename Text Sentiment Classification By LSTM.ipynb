{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaviWhite/ML/blob/main/Text%20Sentiment%20Classification%20By%20LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Sentiment Classification By LSTM"
      ],
      "metadata": {
        "id": "o2ezdrUSPaXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "path_prefix = './'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T04:06:47.191620Z",
          "iopub.execute_input": "2023-03-26T04:06:47.191988Z",
          "iopub.status.idle": "2023-03-26T04:06:47.198527Z",
          "shell.execute_reply.started": "2023-03-26T04:06:47.191953Z",
          "shell.execute_reply": "2023-03-26T04:06:47.196937Z"
        },
        "trusted": true,
        "id": "aLZ19d11PaXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "4vJIBKhhPaXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def load_training_data(path='/content/Train_label.txt'):\n",
        "    # Read training data\n",
        "    if 'Train_label' in path:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "            lines = [line.strip('\\n').split(' ') for line in lines]\n",
        "        x = [line[2:] for line in lines]\n",
        "        y = [line[0] for line in lines]\n",
        "        return x, y\n",
        "    else:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "            x = [line.strip('\\n').split(' ') for line in lines]\n",
        "        return x\n",
        "\n",
        "def load_testing_data(path='/content/Test.txt'):\n",
        "    # Read testing data\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "        X = [\"\".join(line.strip('\\n').split(\",\")[1:]).strip() for line in lines[1:]]\n",
        "        X = [sen.split(' ') for sen in X]\n",
        "    return X\n",
        "\n",
        "def evaluation(outputs, labels):\n",
        "    #outputs => probability (float)\n",
        "    #labels => labels\n",
        "    outputs[outputs>=0.5] = 1 # Negtive Sentiment\n",
        "    outputs[outputs<0.5] = 0 # Positive Sentiment\n",
        "    correct = torch.sum(torch.eq(outputs, labels)).item()\n",
        "    return correct"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T04:06:47.201381Z",
          "iopub.execute_input": "2023-03-26T04:06:47.201789Z",
          "iopub.status.idle": "2023-03-26T04:06:47.233839Z",
          "shell.execute_reply.started": "2023-03-26T04:06:47.201752Z",
          "shell.execute_reply": "2023-03-26T04:06:47.232653Z"
        },
        "trusted": true,
        "id": "KjfIPADtPaXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Word to Vector"
      ],
      "metadata": {
        "id": "FLxjjumpPaXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import argparse\n",
        "from gensim.models import word2vec\n",
        "\n",
        "def train_word2vec(x):\n",
        "    model = word2vec.Word2Vec(x, vector_size=250, window=5, min_count=5, workers=12)\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"loading training data ...\")\n",
        "    train_x, y = load_training_data('/content/Train_label.txt')\n",
        "    train_x_no_label = load_training_data('/content/Train_nolabel.txt')\n",
        "\n",
        "    print(\"loading testing data ...\")\n",
        "    test_x = load_testing_data('/content/Test.txt')\n",
        "\n",
        "    model = train_word2vec(train_x + train_x_no_label + test_x)\n",
        "\n",
        "    print(\"saving model ...\")\n",
        "    model.save(os.path.join(path_prefix, '/w2v_all.model'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T04:06:47.235314Z",
          "iopub.execute_input": "2023-03-26T04:06:47.236209Z",
          "iopub.status.idle": "2023-03-26T04:11:17.735726Z",
          "shell.execute_reply.started": "2023-03-26T04:06:47.236146Z",
          "shell.execute_reply": "2023-03-26T04:11:17.734588Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxJtUq-0PaXL",
        "outputId": "4780ea32-21c7-4a18-f350-ee75735b40c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading training data ...\n",
            "loading testing data ...\n",
            "saving model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocess\n"
      ],
      "metadata": {
        "id": "FbLBWNrkPaXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "class Preprocess():\n",
        "    def __init__(self, sentences, sen_len, w2v_path=\"./w2v.model\"):\n",
        "        self.w2v_path = w2v_path\n",
        "        self.sentences = sentences\n",
        "        self.sen_len = sen_len\n",
        "        self.idx2word = []\n",
        "        self.word2idx = {}\n",
        "        self.embedding_matrix = []\n",
        "    def get_w2v_model(self):\n",
        "        # load word to vector model\n",
        "        self.embedding = Word2Vec.load(self.w2v_path)\n",
        "        self.embedding_dim = self.embedding.vector_size\n",
        "    def add_embedding(self, word):\n",
        "        # add word into embedding\n",
        "        vector = torch.empty(1, self.embedding_dim)\n",
        "        torch.nn.init.uniform_(vector)\n",
        "        self.word2idx[word] = len(self.word2idx)\n",
        "        self.idx2word.append(word)\n",
        "        self.embedding_matrix = torch.cat([self.embedding_matrix, vector], 0)\n",
        "    def make_embedding(self, load=True):\n",
        "        print(\"Get embedding ...\")\n",
        "        if load:\n",
        "            print(\"loading word to vec model ...\")\n",
        "            self.get_w2v_model()\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        for i, word in enumerate(self.embedding.wv.key_to_index):\n",
        "            print('get words #{}'.format(i+1), end='\\r')\n",
        "            self.word2idx[word] = len(self.word2idx)\n",
        "            self.idx2word.append(word)\n",
        "            self.embedding_matrix.append(self.embedding.wv[word])\n",
        "        print('')\n",
        "        self.embedding_matrix = torch.tensor(self.embedding_matrix)\n",
        "        self.add_embedding(\"<PAD>\")\n",
        "        self.add_embedding(\"<UNK>\")\n",
        "        print(\"total words: {}\".format(len(self.embedding_matrix)))\n",
        "        return self.embedding_matrix\n",
        "    def pad_sequence(self, sentence):\n",
        "        if len(sentence) > self.sen_len:\n",
        "            sentence = sentence[:self.sen_len]\n",
        "        else:\n",
        "            pad_len = self.sen_len - len(sentence)\n",
        "            for _ in range(pad_len):\n",
        "                sentence.append(self.word2idx[\"<PAD>\"])\n",
        "        assert len(sentence) == self.sen_len\n",
        "        return sentence\n",
        "    def sentence_word2idx(self):\n",
        "        sentence_list = []\n",
        "        for i, sen in enumerate(self.sentences):\n",
        "            print('sentence count #{}'.format(i+1), end='\\r')\n",
        "            sentence_idx = []\n",
        "            for word in sen:\n",
        "                if (word in self.word2idx.keys()):\n",
        "                    sentence_idx.append(self.word2idx[word])\n",
        "                else:\n",
        "                    sentence_idx.append(self.word2idx[\"<UNK>\"])\n",
        "            sentence_idx = self.pad_sequence(sentence_idx)\n",
        "            sentence_list.append(sentence_idx)\n",
        "        return torch.LongTensor(sentence_list)\n",
        "    def labels_to_tensor(self, y):\n",
        "        # turn labels into tensors\n",
        "        y = [int(label) for label in y]\n",
        "        return torch.LongTensor(y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T04:11:17.738232Z",
          "iopub.execute_input": "2023-03-26T04:11:17.739309Z",
          "iopub.status.idle": "2023-03-26T04:11:17.760103Z",
          "shell.execute_reply.started": "2023-03-26T04:11:17.739267Z",
          "shell.execute_reply": "2023-03-26T04:11:17.758808Z"
        },
        "trusted": true,
        "id": "PtUsfmBXPaXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "GpTEDlfFPaXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "class TwitterDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Expected data shape like:(data_num, data_len)\n",
        "    Data can be a list of numpy array or a list of lists\n",
        "    input data shape : (data_num, seq_len, feature_dim)\n",
        "\n",
        "    __len__ will return the number of data\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.label = y\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is None: return self.data[idx]\n",
        "        return self.data[idx], self.label[idx]\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T04:11:17.761965Z",
          "iopub.execute_input": "2023-03-26T04:11:17.763009Z",
          "iopub.status.idle": "2023-03-26T04:11:17.776425Z",
          "shell.execute_reply.started": "2023-03-26T04:11:17.762972Z",
          "shell.execute_reply": "2023-03-26T04:11:17.775151Z"
        },
        "trusted": true,
        "id": "SCyV5DcqPaXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model"
      ],
      "metadata": {
        "id": "WkPUGwJ8PaXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "class LSTM_Net(nn.Module):\n",
        "    def __init__(self, embedding, embedding_dim, hidden_dim, num_layers, dropout=0.5, fix_embedding=True):\n",
        "        super(LSTM_Net, self).__init__()\n",
        "        # embedding layer\n",
        "        self.embedding = torch.nn.Embedding(embedding.size(0),embedding.size(1))\n",
        "        self.embedding.weight = torch.nn.Parameter(embedding)\n",
        "        # Whether fix embedding\n",
        "        self.embedding.weight.requires_grad = False if fix_embedding else True\n",
        "        self.embedding_dim = embedding.size(1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.classifier = nn.Sequential( nn.Dropout(dropout),\n",
        "                          nn.Linear(hidden_dim, 1),\n",
        "                          nn.Sigmoid() )\n",
        "    def forward(self, inputs):\n",
        "        inputs = self.embedding(inputs)\n",
        "        x, _ = self.lstm(inputs, None)\n",
        "        # dimension of x (batch, seq_len, hidden_size)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T04:11:17.778229Z",
          "iopub.execute_input": "2023-03-26T04:11:17.779163Z",
          "iopub.status.idle": "2023-03-26T04:11:17.793047Z",
          "shell.execute_reply.started": "2023-03-26T04:11:17.779108Z",
          "shell.execute_reply": "2023-03-26T04:11:17.791548Z"
        },
        "trusted": true,
        "id": "0WIuslkZPaXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Training"
      ],
      "metadata": {
        "id": "WByO16kdPaXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def training(batch_size, n_epoch, lr, model_dir, train, valid, model, device):\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print('\\nstart training, parameter total:{}, trainable:{}\\n'.format(total, trainable))\n",
        "    model.train() # set training mode\n",
        "    criterion = nn.BCELoss() # Define loss function\n",
        "    t_batch = len(train)\n",
        "    v_batch = len(valid)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr) # set optimizer as Adam (you can change it)\n",
        "    total_loss, total_acc, best_acc = 0, 0, 0\n",
        "    epoch_num=range(1,6)#1,2,3,4,5\n",
        "    train_loss=[]\n",
        "    valid_loss=[]\n",
        "    for epoch in range(n_epoch):\n",
        "        total_loss, total_acc = 0, 0\n",
        "\n",
        "        # For training\n",
        "        model.train() #set training mode\n",
        "        for i, (inputs, labels) in enumerate(train):\n",
        "            inputs = inputs.to(device, dtype=torch.long) # set device \"cuda\"\n",
        "            labels = labels.to(device, dtype=torch.float) # set device \"cuda\"\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.squeeze()\n",
        "            model.train()\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            correct = evaluation(outputs, labels) # calculate accuracy\n",
        "            total_acc += (correct / batch_size)\n",
        "            total_loss += loss.item()\n",
        "            print('[ Epoch{}: {}/{} ] loss:{:.3f} acc:{:.3f} '.format(\n",
        "            \tepoch+1, i+1, t_batch, loss.item(), correct*100/batch_size), end='\\r')\n",
        "        print('\\nTrain | Loss:{:.5f} Acc: {:.3f}'.format(total_loss/t_batch, total_acc/t_batch*100))\n",
        "        train_loss.append(total_loss/t_batch)\n",
        "\n",
        "        # For validation\n",
        "        model.eval() # set validation mode\n",
        "        with torch.no_grad():\n",
        "            total_loss, total_acc = 0, 0\n",
        "            for i, (inputs, labels) in enumerate(valid):\n",
        "                inputs = inputs.to(device, dtype=torch.long) # set device \"cuda\"\n",
        "                labels = labels.to(device, dtype=torch.float) # set device \"cuda\"\n",
        "                outputs = model(inputs)\n",
        "                outputs = outputs.squeeze()\n",
        "                loss = criterion(outputs, labels)\n",
        "                correct = evaluation(outputs, labels)\n",
        "                total_acc += (correct / batch_size)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            print(\"Valid | Loss:{:.5f} Acc: {:.3f} \".format(total_loss/v_batch, total_acc/v_batch*100))\n",
        "            if total_acc > best_acc:\n",
        "                # if the result of validation is better than previous model, save the new model\n",
        "                best_acc = total_acc\n",
        "                torch.save(model, \"{}/ckpt.model\".format(model_dir))\n",
        "                print('saving model with acc {:.3f}'.format(total_acc/v_batch*100))\n",
        "        print('-----------------------------------------------')\n",
        "        valid_loss.append(total_loss/v_batch)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T04:11:17.798328Z",
          "iopub.execute_input": "2023-03-26T04:11:17.801000Z",
          "iopub.status.idle": "2023-03-26T04:11:17.823258Z",
          "shell.execute_reply.started": "2023-03-26T04:11:17.800965Z",
          "shell.execute_reply": "2023-03-26T04:11:17.821928Z"
        },
        "trusted": true,
        "id": "2_YrR0X1PaXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "6yyUanNzPaXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def testing(batch_size, test_loader, model, device):\n",
        "    model.eval()\n",
        "    ret_output = []\n",
        "    with torch.no_grad():\n",
        "        for i, inputs in enumerate(test_loader):\n",
        "            inputs = inputs.to(device, dtype=torch.long)\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.squeeze()\n",
        "            outputs[outputs>=0.5] = 1\n",
        "            outputs[outputs<0.5] = 0\n",
        "            ret_output += outputs.int().tolist()\n",
        "\n",
        "    return ret_output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T04:11:17.827964Z",
          "iopub.execute_input": "2023-03-26T04:11:17.830603Z",
          "iopub.status.idle": "2023-03-26T04:11:17.841489Z",
          "shell.execute_reply.started": "2023-03-26T04:11:17.830560Z",
          "shell.execute_reply": "2023-03-26T04:11:17.840155Z"
        },
        "trusted": true,
        "id": "3z7a4WHEPaXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter setting + Train"
      ],
      "metadata": {
        "id": "V-65rtvaPaXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from gensim.models import word2vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# set data path\n",
        "train_with_label = os.path.join(path_prefix, '/content/Train_label.txt')\n",
        "train_no_label = os.path.join(path_prefix, '/content/Train_nolabel.txt')\n",
        "testing_data = os.path.join(path_prefix, '/content/Test.txt')\n",
        "w2v_path = os.path.join(path_prefix, '/w2v_all.model')\n",
        "\n",
        "\n",
        "sen_len = 30\n",
        "fix_embedding = True # fix embedding during training\n",
        "batch_size = 256\n",
        "#batch_size = 128\n",
        "#batch_size = 32\n",
        "#batch_size = 64\n",
        "#epoch = 2\n",
        "epoch = 5\n",
        "#epoch = 10\n",
        "#lr = 0.0001\n",
        "lr = 0.001\n",
        "model_dir = path_prefix\n",
        "\n",
        "print(\"loading data ...\")\n",
        "train_x, y = load_training_data(train_with_label)\n",
        "train_x_no_label = load_training_data(train_no_label)\n",
        "\n",
        "# Preprocessing\n",
        "preprocess = Preprocess(train_x, sen_len, w2v_path=w2v_path)\n",
        "embedding = preprocess.make_embedding(load=True)\n",
        "train_x = preprocess.sentence_word2idx()\n",
        "y = preprocess.labels_to_tensor(y)\n",
        "\n",
        "\n",
        "model = LSTM_Net(embedding, embedding_dim=250, hidden_dim=125, num_layers=1, dropout=0.5, fix_embedding=fix_embedding)\n",
        "model = model.to(device) # device為\"cuda\"，model使用GPU來訓練(餵進去的inputs也需要是cuda tensor)\n",
        "\n",
        "#X_train, X_val, y_train, y_val = train_x[:130000], train_x[130000:], y[:130000], y[130000:]\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_x, y, test_size = 0.1, random_state = 1, stratify = y)\n",
        "# change the sample size for trainning and validation\n",
        "\n",
        "train_dataset = TwitterDataset(X=X_train, y=y_train)\n",
        "val_dataset = TwitterDataset(X=X_val, y=y_val)\n",
        "\n",
        "# transfor data into batch of tensors\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                             batch_size = batch_size,\n",
        "                             shuffle = True,\n",
        "                             num_workers = 8)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n",
        "                           batch_size = batch_size,\n",
        "                           shuffle = False,\n",
        "                           num_workers = 8)\n",
        "\n",
        "#train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "#                            batch_size = batch_size,\n",
        "#                            shuffle = True,\n",
        "#                            num_workers = 0)\n",
        "\n",
        "#val_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n",
        "#                            batch_size = batch_size,\n",
        "#                           shuffle = False,\n",
        "#                           num_workers = 0)\n",
        "\n",
        "# Begin Training\n",
        "training(batch_size, epoch, lr, model_dir, train_loader, val_loader, model, device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T04:11:17.848238Z",
          "iopub.execute_input": "2023-03-26T04:11:17.850682Z",
          "iopub.status.idle": "2023-03-26T04:17:37.104006Z",
          "shell.execute_reply.started": "2023-03-26T04:11:17.850646Z",
          "shell.execute_reply": "2023-03-26T04:17:37.101287Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuKCw-3ZPaXS",
        "outputId": "ee82499c-a3f4-4bbb-d7a0-fe06994519af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data ...\n",
            "Get embedding ...\n",
            "loading word to vec model ...\n",
            "get words #158703\n",
            "total words: 158705\n",
            "\n",
            "start training, parameter total:39864876, trainable:188626\n",
            "\n",
            "\n",
            "Train | Loss:0.45981 Acc: 77.726\n",
            "Valid | Loss:0.41233 Acc: 80.523 \n",
            "saving model with acc 80.523\n",
            "-----------------------------------------------\n",
            "\n",
            "Train | Loss:0.39132 Acc: 82.314\n",
            "Valid | Loss:0.39259 Acc: 81.822 \n",
            "saving model with acc 81.822\n",
            "-----------------------------------------------\n",
            "\n",
            "Train | Loss:0.36888 Acc: 83.465\n",
            "Valid | Loss:0.38291 Acc: 82.372 \n",
            "saving model with acc 82.372\n",
            "-----------------------------------------------\n",
            "\n",
            "Train | Loss:0.35262 Acc: 84.377\n",
            "Valid | Loss:0.38124 Acc: 82.447 \n",
            "saving model with acc 82.447\n",
            "-----------------------------------------------\n",
            "\n",
            "Train | Loss:0.33614 Acc: 85.263\n",
            "Valid | Loss:0.38762 Acc: 82.250 \n",
            "-----------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict and save to csv file"
      ],
      "metadata": {
        "id": "m_j1FDr1PaXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"loading testing data ...\")\n",
        "test_x = load_testing_data(testing_data)\n",
        "preprocess = Preprocess(test_x, sen_len, w2v_path=w2v_path)\n",
        "embedding = preprocess.make_embedding(load=True)\n",
        "test_x = preprocess.sentence_word2idx()\n",
        "test_dataset = TwitterDataset(X=test_x, y=None)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                            batch_size = batch_size,\n",
        "                            shuffle = False,\n",
        "                            num_workers = 8)\n",
        "\n",
        "#test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "#                           batch_size = batch_size,\n",
        "#                           shuffle = False,\n",
        "#                           num_workers = 0)\n",
        "print('\\nload model ...')\n",
        "model = torch.load(os.path.join(model_dir, '/content/ckpt.model'))\n",
        "outputs = testing(batch_size, test_loader, model, device)\n",
        "\n",
        "# save as csv\n",
        "tmp = pd.DataFrame({\"id\":[str(i) for i in range(len(test_x))],\"labels\":outputs})\n",
        "print(\"save csv ...\")\n",
        "tmp.to_csv(os.path.join(path_prefix, 'predict.csv'), index=False)\n",
        "print(\"Finish Predicting\")"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2023-03-26T04:20:23.113614Z",
          "iopub.execute_input": "2023-03-26T04:20:23.114756Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms3m7cX1PaXT",
        "outputId": "54eeb217-fdcd-4407-c75b-e9ec6174f152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading testing data ...\n",
            "Get embedding ...\n",
            "loading word to vec model ...\n",
            "get words #158703\n",
            "total words: 158705\n",
            "\n",
            "load model ...\n",
            "save csv ...\n",
            "Finish Predicting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hint\n",
        "* Optimizer\n",
        "* learning rate\n",
        "* epoch\n",
        "* batch size\n",
        "* Activation function\n",
        "* Self-Training for unlabel training data"
      ],
      "metadata": {
        "id": "1I2QE3bePaXT"
      }
    }
  ]
}